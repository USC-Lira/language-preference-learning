{
  "algorithm": "SAC",
  "algorithm_kwargs": {
    "batch_size": 128,
    "eval_max_path_length": 500,
    "expl_max_path_length": 500,
    "min_num_steps_before_training": 3300,
    "num_epochs": 500,
    "num_eval_steps_per_epoch": 2500,
    "num_expl_steps_per_train_loop": 2500,
    "num_trains_per_train_loop": 1000
  },
  "eval_environment_kwargs": {
    "control_freq": 20,
    "controller": "OSC_POSITION",
    "env_name": "LiftModded",
    "hard_reset": false,
    "horizon": 500,
    "ignore_done": true,
    "reward_scale": 1.0,
    "robots": [
      "Jaco"
    ],
    "weights": [
      -0.23413696,
      0.39257975,
      -0.92918467,
      0.07983181,
      -0.1595165
    ]
  },
  "expl_environment_kwargs": {
    "control_freq": 20,
    "controller": "OSC_POSITION",
    "env_name": "LiftModded",
    "hard_reset": false,
    "horizon": 500,
    "ignore_done": true,
    "reward_scale": 1.0,
    "robots": [
      "Jaco"
    ],
    "weights": [
      -0.23413696,
      0.39257975,
      -0.92918467,
      0.07983181,
      -0.1595165
    ]
  },
  "policy_kwargs": {
    "hidden_sizes": [
      256,
      256
    ]
  },
  "qf_kwargs": {
    "hidden_sizes": [
      256,
      256
    ]
  },
  "replay_buffer_size": 1000000,
  "seed": 251,
  "trainer_kwargs": {
    "discount": 0.99,
    "policy_lr": 0.001,
    "qf_lr": 0.0005,
    "reward_scale": 1.0,
    "soft_target_tau": 0.005,
    "target_update_period": 5,
    "use_automatic_entropy_tuning": true
  },
  "version": "normal"
}